"""
Image Search & Retrieval Service

This service handles:
1. Image upload and embedding generation (CLIP)
2. Text-to-image search (semantic search)
3. Image-to-image search (similarity search)
4. Hybrid search (combining text + image)

Technology Stack:
- CLIP (clip-vit-base-patch32) - 512 dimensions
- pgvector for similarity search
- PyTorch for model inference
"""

import numpy as np
from typing import Optional, List, Dict, Any, Tuple
from datetime import datetime
import asyncio
from pathlib import Path
import logging
import time

# Logging
logger = logging.getLogger(__name__)

# Config
from src.infrastructure.config import Settings, get_settings

# PIL Image import (always needed for type hints)
from PIL import Image

# CLIP imports
try:
    import torch
    from transformers import CLIPProcessor, CLIPModel
    import io
    CLIP_AVAILABLE = True
except ImportError as e:
    CLIP_AVAILABLE = False
    logger.warning(f"CLIP dependencies not available: {e}")

# Database imports
import asyncpg
from pgvector.asyncpg import register_vector


class CLIPEmbeddingExtractor:
    """
    CLIP model for extracting image and text embeddings
    """

    def __init__(self, model_name: str = "openai/clip-vit-base-patch32", device: str = "cpu"):
        """
        Initialize CLIP model

        Args:
            model_name: HuggingFace model name
            device: 'cpu' or 'cuda'
        """
        if not CLIP_AVAILABLE:
            raise RuntimeError("CLIP dependencies not installed")

        self.model_name = model_name
        self.device = device

        logger.info(f"Loading CLIP model: {model_name} on {device}")
        self.model = CLIPModel.from_pretrained(model_name).to(device)
        self.processor = CLIPProcessor.from_pretrained(model_name)
        self.model.eval()  # Set to evaluation mode
        logger.info("âœ… CLIP model loaded successfully")

    def extract_image_embedding(self, image: Image.Image) -> np.ndarray:
        """
        Extract embedding from image

        Args:
            image: PIL Image

        Returns:
            512-dim embedding vector
        """
        with torch.no_grad():
            inputs = self.processor(images=image, return_tensors="pt").to(self.device)
            image_features = self.model.get_image_features(**inputs)
            # Normalize embedding
            image_features = image_features / image_features.norm(dim=-1, keepdim=True)
            embedding = image_features.cpu().numpy()[0]

        return embedding

    def extract_text_embedding(self, text: str) -> np.ndarray:
        """
        Extract embedding from text

        Args:
            text: Text query

        Returns:
            512-dim embedding vector
        """
        with torch.no_grad():
            inputs = self.processor(text=[text], return_tensors="pt", padding=True).to(
                self.device
            )
            text_features = self.model.get_text_features(**inputs)
            # Normalize embedding
            text_features = text_features / text_features.norm(dim=-1, keepdim=True)
            embedding = text_features.cpu().numpy()[0]

        return embedding

    def extract_batch_embeddings(
        self, images: List[Image.Image]
    ) -> List[np.ndarray]:
        """
        Extract embeddings for multiple images in batch

        Args:
            images: List of PIL Images

        Returns:
            List of 512-dim embeddings
        """
        with torch.no_grad():
            inputs = self.processor(images=images, return_tensors="pt").to(self.device)
            image_features = self.model.get_image_features(**inputs)
            # Normalize embeddings
            image_features = image_features / image_features.norm(dim=-1, keepdim=True)
            embeddings = image_features.cpu().numpy()

        return [emb for emb in embeddings]


class ImageSearchService:
    """Main image search service"""

    def __init__(
        self,
        settings: Optional[Settings] = None,
    ):
        """
        Initialize image search service

        Args:
            settings: Application settings
        """
        self.settings = settings or get_settings()

        # Components
        self.clip_extractor: Optional[CLIPEmbeddingExtractor] = None

        # Connections
        self.db_pool: Optional[asyncpg.Pool] = None

    async def initialize(self):
        """Initialize all components"""
        logger.info("Initializing Image Search Service...")

        # 1. Initialize CLIP model
        device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"Using device: {device}")

        self.clip_extractor = CLIPEmbeddingExtractor(
            model_name="openai/clip-vit-base-patch32", device=device
        )

        # 2. Initialize database connection pool
        logger.info("Connecting to PostgreSQL...")
        self.db_pool = await asyncpg.create_pool(
            self.settings.asyncpg_url,
            min_size=2,
            max_size=10,
        )
        # Register pgvector type
        async with self.db_pool.acquire() as conn:
            await register_vector(conn)
        logger.info("âœ… Database connected")

        logger.info("ðŸš€ Image Search Service initialized successfully!")

    async def shutdown(self):
        """Cleanup resources"""
        logger.info("Shutting down Image Search Service...")

        if self.db_pool:
            await self.db_pool.close()

        # Clear CLIP model from memory
        if self.clip_extractor:
            del self.clip_extractor.model
            del self.clip_extractor.processor
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

        logger.info("âœ… Service shutdown complete")

    async def upload_image(
        self,
        image: Image.Image,
        image_url: str,
        hotel_id: Optional[int] = None,
        room_id: Optional[int] = None,
        destination_id: Optional[int] = None,
        description: Optional[str] = None,
        tags: Optional[List[str]] = None,
        is_primary: bool = False,
    ) -> Dict[str, Any]:
        """
        Upload image and generate embedding

        Args:
            image: PIL Image
            image_url: URL where image is stored
            hotel_id: Associated hotel ID
            room_id: Associated room ID
            destination_id: Associated destination ID
            description: Image description
            tags: Image tags
            is_primary: Whether this is primary image

        Returns:
            {
                "success": bool,
                "image_id": int,
                "message": str,
            }
        """
        try:
            # 1. Extract embedding
            embedding = self.clip_extractor.extract_image_embedding(image)

            # 2. Get image metadata
            width, height = image.size
            image_format = image.format or "UNKNOWN"

            # 3. Save to database
            async with self.db_pool.acquire() as conn:
                image_id = await conn.fetchval(
                    """
                    INSERT INTO Image (
                        hotel_id, room_id, destination_id,
                        image_url, image_description, image_tags,
                        is_primary, image_width, image_height,
                        image_format, image_embedding, embedding_model,
                        embedding_created_at
                    ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13)
                    RETURNING image_id
                    """,
                    hotel_id,
                    room_id,
                    destination_id,
                    image_url,
                    description,
                    tags,
                    is_primary,
                    width,
                    height,
                    image_format,
                    embedding.tolist(),
                    "clip-vit-base-patch32",
                    datetime.utcnow(),
                )

            logger.info(
                f"âœ… Image uploaded: image_id={image_id}, size={width}x{height}"
            )

            return {
                "success": True,
                "image_id": image_id,
                "message": "Image uploaded and indexed successfully",
                "embedding_generated": True,
            }

        except Exception as e:
            logger.error(f"Error uploading image: {e}", exc_info=True)
            return {
                "success": False,
                "message": f"Upload error: {str(e)}",
                "embedding_generated": False,
            }

    async def search_by_text(
        self,
        query: str,
        entity_type: Optional[str] = None,
        entity_id: Optional[int] = None,
        limit: int = 10,
        min_similarity: float = 0.3,
    ) -> Dict[str, Any]:
        """
        Search images using text query

        Args:
            query: Text search query
            entity_type: Filter by entity type ('hotel', 'room', 'destination')
            entity_id: Filter by specific entity ID
            limit: Number of results
            min_similarity: Minimum similarity threshold

        Returns:
            {
                "success": bool,
                "query": str,
                "results": List[dict],
                "total": int,
                "search_time_ms": float,
            }
        """
        start_time = time.time()

        try:
            # 1. Extract text embedding
            query_embedding = self.clip_extractor.extract_text_embedding(query)

            # 2. Build SQL query
            sql = """
                SELECT
                    i.image_id,
                    i.image_url,
                    i.image_description,
                    i.image_tags,
                    i.is_primary,
                    i.image_width,
                    i.image_height,
                    i.embedding_model,
                    i.created_at,
                    -- Similarity score
                    1 - (i.image_embedding <=> $1::vector) as similarity,
                    -- Hotel info
                    h.hotel_id,
                    h.name as hotel_name,
                    h.rating as hotel_rating,
                    h.address as hotel_address,
                    h.thumbnail as hotel_thumbnail,
                    -- Room info
                    r.room_id,
                    r.room_name,
                    r.room_status,
                    -- Destination info
                    d.destination_id,
                    d.name as destination_name,
                    d.location as destination_location,
                    d.type as destination_type
                FROM Image i
                LEFT JOIN Hotel h ON i.hotel_id = h.hotel_id
                LEFT JOIN Room r ON i.room_id = r.room_id
                LEFT JOIN Destination d ON i.destination_id = d.destination_id
                WHERE i.image_embedding IS NOT NULL
            """

            params = [query_embedding.tolist()]
            param_idx = 2

            # Add filters
            if entity_type and entity_id:
                if entity_type == "hotel":
                    sql += f" AND i.hotel_id = ${param_idx}"
                elif entity_type == "room":
                    sql += f" AND i.room_id = ${param_idx}"
                elif entity_type == "destination":
                    sql += f" AND i.destination_id = ${param_idx}"
                params.append(entity_id)
                param_idx += 1

            # Add similarity threshold and ordering
            sql += f"""
                AND (1 - (i.image_embedding <=> $1::vector)) >= ${param_idx}
                ORDER BY i.image_embedding <=> $1::vector
                LIMIT ${param_idx + 1}
            """
            params.extend([min_similarity, limit])

            # 3. Execute query
            async with self.db_pool.acquire() as conn:
                rows = await conn.fetch(sql, *params)

            # 4. Format results
            results = []
            for row in rows:
                result = {
                    "similarity": float(row["similarity"]),
                    "image": {
                        "image_id": row["image_id"],
                        "image_url": row["image_url"],
                        "image_description": row["image_description"],
                        "image_tags": row["image_tags"],
                        "is_primary": row["is_primary"],
                        "image_width": row["image_width"],
                        "image_height": row["image_height"],
                        "embedding_model": row["embedding_model"],
                        "created_at": row["created_at"],
                    },
                }

                # Add hotel info if present
                if row["hotel_id"]:
                    result["hotel"] = {
                        "hotel_id": row["hotel_id"],
                        "hotel_name": row["hotel_name"],
                        "hotel_rating": row["hotel_rating"],
                        "hotel_address": row["hotel_address"],
                        "hotel_thumbnail": row["hotel_thumbnail"],
                    }

                # Add room info if present
                if row["room_id"]:
                    result["room"] = {
                        "room_id": row["room_id"],
                        "room_name": row["room_name"],
                        "room_status": row["room_status"],
                    }

                # Add destination info if present
                if row["destination_id"]:
                    result["destination"] = {
                        "destination_id": row["destination_id"],
                        "destination_name": row["destination_name"],
                        "destination_location": row["destination_location"],
                        "destination_type": row["destination_type"],
                    }

                results.append(result)

            search_time_ms = (time.time() - start_time) * 1000

            logger.info(
                f"âœ… Text search: query='{query}', found={len(results)}, time={search_time_ms:.2f}ms"
            )

            return {
                "success": True,
                "query": query,
                "results": results,
                "total": len(results),
                "search_time_ms": search_time_ms,
            }

        except Exception as e:
            logger.error(f"Error in text search: {e}", exc_info=True)
            search_time_ms = (time.time() - start_time) * 1000
            return {
                "success": False,
                "query": query,
                "results": [],
                "total": 0,
                "search_time_ms": search_time_ms,
            }

    async def search_by_image(
        self,
        image: Image.Image,
        entity_type: Optional[str] = None,
        entity_id: Optional[int] = None,
        limit: int = 10,
        min_similarity: float = 0.5,
    ) -> Dict[str, Any]:
        """
        Search similar images using an uploaded image

        Args:
            image: Query image (PIL Image)
            entity_type: Filter by entity type
            entity_id: Filter by specific entity ID
            limit: Number of results
            min_similarity: Minimum similarity threshold

        Returns:
            Same format as search_by_text
        """
        start_time = time.time()

        try:
            # 1. Extract image embedding
            query_embedding = self.clip_extractor.extract_image_embedding(image)

            # 2. Use same SQL query as text search (reuse logic)
            # Build SQL query
            sql = """
                SELECT
                    i.image_id,
                    i.image_url,
                    i.image_description,
                    i.image_tags,
                    i.is_primary,
                    i.image_width,
                    i.image_height,
                    i.embedding_model,
                    i.created_at,
                    1 - (i.image_embedding <=> $1::vector) as similarity,
                    h.hotel_id, h.name as hotel_name, h.rating as hotel_rating,
                    h.address as hotel_address, h.thumbnail as hotel_thumbnail,
                    r.room_id, r.room_name, r.room_status,
                    d.destination_id, d.name as destination_name,
                    d.location as destination_location, d.type as destination_type
                FROM Image i
                LEFT JOIN Hotel h ON i.hotel_id = h.hotel_id
                LEFT JOIN Room r ON i.room_id = r.room_id
                LEFT JOIN Destination d ON i.destination_id = d.destination_id
                WHERE i.image_embedding IS NOT NULL
            """

            params = [query_embedding.tolist()]
            param_idx = 2

            if entity_type and entity_id:
                if entity_type == "hotel":
                    sql += f" AND i.hotel_id = ${param_idx}"
                elif entity_type == "room":
                    sql += f" AND i.room_id = ${param_idx}"
                elif entity_type == "destination":
                    sql += f" AND i.destination_id = ${param_idx}"
                params.append(entity_id)
                param_idx += 1

            sql += f"""
                AND (1 - (i.image_embedding <=> $1::vector)) >= ${param_idx}
                ORDER BY i.image_embedding <=> $1::vector
                LIMIT ${param_idx + 1}
            """
            params.extend([min_similarity, limit])

            # 3. Execute query
            async with self.db_pool.acquire() as conn:
                rows = await conn.fetch(sql, *params)

            # 4. Format results (same as text search)
            results = []
            for row in rows:
                result = {
                    "similarity": float(row["similarity"]),
                    "image": {
                        "image_id": row["image_id"],
                        "image_url": row["image_url"],
                        "image_description": row["image_description"],
                        "image_tags": row["image_tags"],
                        "is_primary": row["is_primary"],
                        "image_width": row["image_width"],
                        "image_height": row["image_height"],
                        "embedding_model": row["embedding_model"],
                        "created_at": row["created_at"],
                    },
                }

                if row["hotel_id"]:
                    result["hotel"] = {
                        "hotel_id": row["hotel_id"],
                        "hotel_name": row["hotel_name"],
                        "hotel_rating": row["hotel_rating"],
                        "hotel_address": row["hotel_address"],
                        "hotel_thumbnail": row["hotel_thumbnail"],
                    }

                if row["room_id"]:
                    result["room"] = {
                        "room_id": row["room_id"],
                        "room_name": row["room_name"],
                        "room_status": row["room_status"],
                    }

                if row["destination_id"]:
                    result["destination"] = {
                        "destination_id": row["destination_id"],
                        "destination_name": row["destination_name"],
                        "destination_location": row["destination_location"],
                        "destination_type": row["destination_type"],
                    }

                results.append(result)

            search_time_ms = (time.time() - start_time) * 1000

            logger.info(
                f"âœ… Image search: found={len(results)}, time={search_time_ms:.2f}ms"
            )

            return {
                "success": True,
                "query": None,
                "results": results,
                "total": len(results),
                "search_time_ms": search_time_ms,
            }

        except Exception as e:
            logger.error(f"Error in image search: {e}", exc_info=True)
            search_time_ms = (time.time() - start_time) * 1000
            return {
                "success": False,
                "query": None,
                "results": [],
                "total": 0,
                "search_time_ms": search_time_ms,
            }

    async def hybrid_search(
        self,
        text_query: Optional[str] = None,
        image: Optional[Image.Image] = None,
        text_weight: float = 0.5,
        image_weight: float = 0.5,
        entity_type: Optional[str] = None,
        limit: int = 10,
        min_similarity: float = 0.3,
    ) -> Dict[str, Any]:
        """
        Hybrid search combining text and image

        Args:
            text_query: Text query
            image: Query image
            text_weight: Weight for text similarity (0-1)
            image_weight: Weight for image similarity (0-1)
            entity_type: Filter by entity type
            limit: Number of results
            min_similarity: Minimum similarity threshold

        Returns:
            Combined search results
        """
        start_time = time.time()

        try:
            # Extract embeddings
            text_emb = None
            image_emb = None

            if text_query:
                text_emb = self.clip_extractor.extract_text_embedding(text_query)

            if image:
                image_emb = self.clip_extractor.extract_image_embedding(image)

            if text_emb is None and image_emb is None:
                return {
                    "success": False,
                    "query": None,
                    "results": [],
                    "total": 0,
                    "search_time_ms": 0,
                }

            # Combine embeddings with weights
            if text_emb is not None and image_emb is not None:
                combined_emb = (text_emb * text_weight + image_emb * image_weight) / (
                    text_weight + image_weight
                )
                # Normalize
                combined_emb = combined_emb / np.linalg.norm(combined_emb)
            elif text_emb is not None:
                combined_emb = text_emb
            else:
                combined_emb = image_emb

            # Use combined embedding for search (same SQL as before)
            # ... (rest is same as search_by_text with combined_emb)

            logger.info(f"âœ… Hybrid search completed")

            return {
                "success": True,
                "query": text_query,
                "results": [],  # TODO: implement
                "total": 0,
                "search_time_ms": (time.time() - start_time) * 1000,
            }

        except Exception as e:
            logger.error(f"Error in hybrid search: {e}", exc_info=True)
            return {
                "success": False,
                "query": text_query,
                "results": [],
                "total": 0,
                "search_time_ms": (time.time() - start_time) * 1000,
            }
