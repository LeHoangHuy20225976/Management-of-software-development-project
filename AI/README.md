# Hotel AI Management System

Há»‡ thá»‘ng AI quáº£n lÃ½ khÃ¡ch sáº¡n vá»›i 4 services chÃ­nh: Computer Vision, Machine Learning, LLM, vÃ  Prefect Orchestration.

## ğŸ“‹ Má»¥c lá»¥c

- [Tá»•ng quan](#tá»•ng-quan)
- [Kiáº¿n trÃºc há»‡ thá»‘ng](#kiáº¿n-trÃºc-há»‡-thá»‘ng)
- [Cáº¥u trÃºc thÆ° má»¥c](#cáº¥u-trÃºc-thÆ°-má»¥c)
- [YÃªu cáº§u há»‡ thá»‘ng](#yÃªu-cáº§u-há»‡-thá»‘ng)
- [CÃ i Ä‘áº·t vÃ  cháº¡y](#cÃ i-Ä‘áº·t-vÃ -cháº¡y)
- [Services vÃ  Ports](#services-vÃ -ports)
- [Quáº£n lÃ½ Prefect Flows](#quáº£n-lÃ½-prefect-flows)
- [Development Workflow](#development-workflow)
- [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Tá»•ng quan

Há»‡ thá»‘ng AI quáº£n lÃ½ khÃ¡ch sáº¡n Ä‘Æ°á»£c xÃ¢y dá»±ng vá»›i kiáº¿n trÃºc microservices, sá»­ dá»¥ng:

- **Computer Vision Service**: Nháº­n diá»‡n khuÃ´n máº·t, OCR, phÃ¢n tÃ­ch camera
- **Machine Learning Service**: Dá»± Ä‘oÃ¡n, recommendation, pricing
- **LLM Service**: Chatbot thÃ´ng minh vá»›i RAG
- **Prefect Service**: Workflow orchestration vÃ  scheduling

**Tech Stack:**
- Docker & Docker Compose
- PostgreSQL vá»›i pgvector (Vector DB)
- Prefect 3.x (Workflow orchestration)
- FastAPI (API services)
- MLflow (ML experiment tracking)
- RabbitMQ (Message queue)
- MinIO (Object storage)
- Redis (Caching)
- Prometheus + Grafana (Monitoring)

### ğŸ¤– RAG (Retrieval-Augmented Generation)

Há»‡ thá»‘ng sá»­ dá»¥ng **LlamaIndex + pgvector** cho LLM Service vá»›i RAG:

- **Vector Database**: PostgreSQL vá»›i pgvector extension (Ä‘Ã£ Ä‘Æ°á»£c setup)
- **Framework**: LlamaIndex cho indexing vÃ  retrieval
- **Use cases**:
  - Chatbot thÃ´ng minh vá»›i knowledge base
  - Semantic search trong tÃ i liá»‡u khÃ¡ch sáº¡n
  - Q&A vá» policies, procedures
  - Personalized recommendations

**Databases cÃ³ pgvector enabled:**
- `vector_db` - Vector embeddings chÃ­nh
- `hotel_db` - Application data vá»›i vector columns
- Táº¥t cáº£ databases Ä‘Ã£ cÃ³ pgvector extension Ä‘Æ°á»£c enable tá»± Ä‘á»™ng

**Example RAG workflow:**
```python
from llama_index import VectorStoreIndex, ServiceContext
from llama_index.vector_stores import PGVectorStore

# Connect to pgvector
vector_store = PGVectorStore.from_params(
    database="vector_db",
    host="postgres",
    password="hotel_password",
    port=5432,
    user="hotel_user",
    table_name="embeddings",
    embed_dim=1536  # OpenAI embedding dimension
)

# Create index and query
index = VectorStoreIndex.from_vector_store(vector_store)
query_engine = index.as_query_engine()
response = query_engine.query("What is the hotel check-in policy?")
```

---

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Frontend/API Gateway                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚  CV Service  â”‚  â”‚ ML Service  â”‚  â”‚ LLM Service â”‚
â”‚  (Port 8001) â”‚  â”‚ (Port 8002) â”‚  â”‚ (Port 8003) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚                 â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Prefect Workflows  â”‚
              â”‚    (Port 4200)      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    â”‚                    â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚ Postgresâ”‚  â”‚   RabbitMQ     â”‚  â”‚     MinIO      â”‚
â”‚ +Vector â”‚  â”‚  (Messages)    â”‚  â”‚   (Storage)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
AI/
â”œâ”€â”€ README.md                      # File nÃ y
â”œâ”€â”€ docker-compose.yml             # Orchestration táº¥t cáº£ services
â”œâ”€â”€ Dockerfile.worker              # Prefect worker image
â”œâ”€â”€ prefect.yaml                   # Prefect deployment config
â”œâ”€â”€ pyproject.toml                 # Python dependencies (uv)
â”œâ”€â”€ .python-version                # Python version
â”œâ”€â”€ .env                           # Environment variables (khÃ´ng commit)
â”‚
â”œâ”€â”€ docs/                          # Documentation
â”‚   â”œâ”€â”€ HOTEL_SYSTEM_ARCHITECTURE.md
â”‚   â”œâ”€â”€ SERVICE_CONNECTIONS.md
â”‚   â”œâ”€â”€ DEPLOYMENT_ROADMAP.md
â”‚   â”œâ”€â”€ CV_SERVICE.md
â”‚   â”œâ”€â”€ ML_SERVICE.md
â”‚   â”œâ”€â”€ LLM_SERVICE.md
â”‚   â””â”€â”€ PREFECT_SERVICE.md
â”‚
â”œâ”€â”€ infrastructure/                # Config files cho services
â”‚   â”œâ”€â”€ postgres/
â”‚   â”‚   â”œâ”€â”€ init-db.sql           # Táº¡o databases
â”‚   â”‚   â””â”€â”€ init-pgvector.sql     # Enable pgvector extension
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â”œâ”€â”€ prometheus.yml        # Prometheus config
â”‚   â”‚   â””â”€â”€ grafana/
â”‚   â”‚       â”œâ”€â”€ dashboards/
â”‚   â”‚       â””â”€â”€ datasources/
â”‚   â”œâ”€â”€ nginx/                     # Nginx config (future)
â”‚   â””â”€â”€ rabbitmq/                  # RabbitMQ config (future)
â”‚
â””â”€â”€ src/                           # Source code
    â”œâ”€â”€ __init__.py
    â”‚
    â”œâ”€â”€ application/               # Business logic layer
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ main.py                # FastAPI application - tá»•ng há»£p táº¥t cáº£ routers
    â”‚   â”‚
    â”‚   â”œâ”€â”€ controllers/           # API endpoints
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ cv/
    â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”‚   â””â”€â”€ router.py      # CV API routes
    â”‚   â”‚   â”œâ”€â”€ ml/
    â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”‚   â””â”€â”€ router.py      # ML API routes
    â”‚   â”‚   â””â”€â”€ llm/
    â”‚   â”‚       â”œâ”€â”€ __init__.py
    â”‚   â”‚       â””â”€â”€ router.py      # LLM API routes
    â”‚   â”‚
    â”‚   â”œâ”€â”€ dtos/                  # Data Transfer Objects
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ cv/                # Request/Response models for CV
    â”‚   â”‚   â”œâ”€â”€ ml/                # Request/Response models for ML
    â”‚   â”‚   â””â”€â”€ llm/               # Request/Response models for LLM
    â”‚   â”‚
    â”‚   â””â”€â”€ services/              # Core services logic
    â”‚       â”œâ”€â”€ __init__.py
    â”‚       â”œâ”€â”€ cv/                # Computer Vision logic
    â”‚       â”œâ”€â”€ ml/                # Machine Learning logic
    â”‚       â””â”€â”€ llm/               # LLM & RAG logic
    â”‚
    â”œâ”€â”€ flow/                      # â­ Prefect Flows (workflows)
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ hello_flow.py          # Example flow
    â”‚
    â”œâ”€â”€ infrastructure/            # Infrastructure code (Python)
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ config.py              # Configuration management
    â”‚
    â””â”€â”€ utils/                     # Utilities
        â”œâ”€â”€ __init__.py
        â””â”€â”€ logger.py              # Logging utilities
```

### ğŸ“ Quy táº¯c Ä‘áº·t tÃªn

- **`infrastructure/`** (root): Config files (YAML, SQL, conf)
- **`src/infrastructure/`**: Python code cho infrastructure (database, clients)
- **`src/flow/`**: Prefect flows (workflows)
- **`src/application/main.py`**: FastAPI app chÃ­nh, tá»•ng há»£p táº¥t cáº£ routers tá»« CV, ML, LLM
- **`src/application/controllers/{service}/router.py`**: API routes cho tá»«ng service (cv, ml, llm)
- **`src/application/services/`**: Business logic cho tá»«ng service
- **`src/application/dtos/`**: Pydantic models cho request/response

---

## ğŸ’» YÃªu cáº§u há»‡ thá»‘ng

### Cháº¡y vá»›i Docker (Recommended)

- **Docker Desktop**: >= 20.x
- **Docker Compose**: >= 2.x
- **RAM**: >= 8GB (recommended 16GB)
- **Disk**: >= 20GB free space

### Cháº¡y local vá»›i uv (Development)

- **Python**: 3.11+
- **uv**: Package manager (cÃ i bÃªn dÆ°á»›i)
- **PostgreSQL**: 16+ vá»›i pgvector extension
- **Redis**: 7+
- **RabbitMQ**: 3+

---

## ğŸš€ CÃ i Ä‘áº·t vÃ  cháº¡y

### PhÆ°Æ¡ng Ã¡n 1: Cháº¡y vá»›i Docker (Recommended - Full Stack)

ÄÃ¢y lÃ  cÃ¡ch **Ä‘Æ¡n giáº£n nháº¥t**, cháº¡y toÃ n bá»™ há»‡ thá»‘ng vá»›i 1 lá»‡nh.

### 1. Clone repository

```bash
cd AI/
```

### 2. Táº¡o file `.env`

```bash
# Táº¡o file .env tá»« template
cat > .env << 'EOF'
# Database
POSTGRES_USER=hotel_user
POSTGRES_PASSWORD=hotel_password
POSTGRES_DB=hotel_db

# Redis
REDIS_PASSWORD=redis_password

# RabbitMQ
RABBITMQ_USER=hotel_user
RABBITMQ_PASSWORD=rabbitmq_password

# MinIO
MINIO_ROOT_USER=minio_admin
MINIO_ROOT_PASSWORD=minio_password_123

# OpenAI (cho LLM service)
OPENAI_API_KEY=your-api-key-here

# Prefect
PREFECT_API_URL=http://prefect-server:4200/api
EOF
```

### 3. Khá»Ÿi Ä‘á»™ng táº¥t cáº£ services

```bash
# Build vÃ  start táº¥t cáº£ containers
docker compose up -d --build

# Xem logs
docker compose logs -f

# Chá»‰ xem logs cá»§a 1 service
docker compose logs -f prefect-worker
```

### 4. Kiá»ƒm tra services Ä‘Ã£ cháº¡y

```bash
docker ps
```

Táº¥t cáº£ containers nÃªn cÃ³ status `Up` hoáº·c `Up (healthy)`.

---

### PhÆ°Æ¡ng Ã¡n 2: Cháº¡y local vá»›i uv (Development - Python Only)

Cháº¡y Python code trá»±c tiáº¿p trÃªn mÃ¡y local, phÃ¹ há»£p cho development vÃ  testing code nhanh.

**âš ï¸ LÆ°u Ã½:** PhÆ°Æ¡ng Ã¡n nÃ y chá»‰ cháº¡y Python code, váº«n cáº§n Docker cho databases (Postgres, Redis, RabbitMQ).

#### 1. CÃ i Ä‘áº·t uv

```bash
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Hoáº·c vá»›i Homebrew (macOS)
brew install uv

# Windows (PowerShell)
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# Kiá»ƒm tra
uv --version
```

#### 2. Setup Python environment

```bash
cd AI/

# Táº¡o virtual environment vÃ  cÃ i dependencies
uv sync

# CÃ i thÃªm dev dependencies (optional)
uv sync --extra dev

# Activate virtual environment
source .venv/bin/activate  # macOS/Linux
# hoáº·c
.venv\Scripts\activate  # Windows
```

#### 3. Start infrastructure services (Docker)

```bash
# Chá»‰ start databases vÃ  infrastructure, KHÃ”NG start AI services
docker compose up -d postgres redis rabbitmq minio mlflow prometheus grafana

# Kiá»ƒm tra
docker ps
```

#### 4. Cháº¡y Prefect flow locally

```bash
# Set environment variables
export PREFECT_API_URL=http://localhost:4200/api
export DATABASE_URL=postgresql://hotel_user:hotel_password@localhost:5433/hotel_db

# Cháº¡y 1 flow trá»±c tiáº¿p
python src/flow/hello_flow.py

# Hoáº·c cháº¡y qua Prefect
prefect flow run src/flow/hello_flow.py:hello_flow
```

#### 5. Cháº¡y FastAPI application locally

```bash
# Cháº¡y toÃ n bá»™ application (táº¥t cáº£ services: CV, ML, LLM)
uvicorn src.application.main:app --reload --port 8000

# Cháº¡y tá»«ng service riÃªng láº» (vÃ­ dá»¥ ML service)
uvicorn src.application.controllers.ml.main:app --reload --port 8002

# Application sáº½ tá»± Ä‘á»™ng load táº¥t cáº£ routers:
# - /cv/*    -> CV service routes
# - /ml/*    -> ML service routes
# - /llm/*   -> LLM service routes

# Xem API docs
open http://localhost:8000/docs
```

#### 6. Test RAG vá»›i LlamaIndex

```bash
# Táº¡o test script
cat > test_rag.py << 'EOF'
from src.application.services.llm.vector_store import HotelVectorStore

# Test connection
store = HotelVectorStore()
print("âœ… Connected to pgvector")

# Index sample documents
docs = ["Check-in time is 3:00 PM", "Free WiFi available"]
store.index_documents(docs)
print("âœ… Indexed documents")

# Query
response = store.query("What time is check-in?")
print(f"ğŸ“ Response: {response}")
EOF

# Cháº¡y test
python test_rag.py
```

#### 7. Quáº£n lÃ½ dependencies vá»›i uv

```bash
# ThÃªm package má»›i
uv add <package-name>

# VÃ­ dá»¥
uv add numpy pandas

# XÃ³a package
uv remove <package-name>

# Update táº¥t cáº£ packages
uv lock --upgrade

# Re-sync sau khi sá»­a pyproject.toml
uv sync

# Export requirements.txt (náº¿u cáº§n)
uv pip compile pyproject.toml -o requirements.txt
```

#### 8. Development workflow vá»›i uv

```bash
# 1. Sá»­a code trong src/
vim src/flow/my_flow.py

# 2. Test ngay láº­p tá»©c
python src/flow/my_flow.py

# 3. KhÃ´ng cáº§n rebuild Docker!
# Code cháº¡y trá»±c tiáº¿p trÃªn mÃ¡y local

# 4. Format code
uv run black src/
uv run ruff check src/

# 5. Run tests
uv run pytest tests/
```

#### 9. So sÃ¡nh Docker vs uv

| TiÃªu chÃ­            | Docker (Full Stack) | uv (Local)               |
| ------------------- | ------------------- | ------------------------ |
| **Setup time**      | LÃ¢u (build images)  | Nhanh (chá»‰ cÃ i packages) |
| **Resource**        | Nhiá»u RAM/CPU       | Ãt hÆ¡n                   |
| **Hot reload**      | Cáº§n mount volumes   | Tá»± Ä‘á»™ng                  |
| **Database**        | TÃ­ch há»£p sáºµn        | Cáº§n Docker riÃªng         |
| **Production-like** | âœ… Giá»‘ng production | âŒ KhÃ¡c production       |
| **Best for**        | Integration testing | Quick prototyping        |

#### 10. Tips

**Khi nÃ o dÃ¹ng uv:**

- Äang develop/debug Python code
- Muá»‘n test nhanh 1 flow
- LÃ m viá»‡c vá»›i Jupyter notebook
- Code completion trong IDE tá»‘t hÆ¡n

**Khi nÃ o dÃ¹ng Docker:**

- Test toÃ n bá»™ há»‡ thá»‘ng
- Deploy lÃªn server
- Share vá»›i team (consistent environment)
- CI/CD pipeline

**Best practice:**

```bash
# Development: Code vá»›i uv
uv sync
python src/flow/my_flow.py

# Testing: Cháº¡y integration test vá»›i Docker
docker compose up -d
pytest tests/integration/

# Production: Deploy vá»›i Docker
docker compose -f docker-compose.prod.yml up -d
```

---

## ğŸŒ Services vÃ  Ports

| Service        | URL                    | Credentials                    | MÃ´ táº£                            |
| -------------- | ---------------------- | ------------------------------ | -------------------------------- |
| **Prefect UI** | http://localhost:4200  | -                              | Workflow orchestration dashboard |
| **Grafana**    | http://localhost:3000  | admin/grafana_password         | Monitoring dashboards            |
| **MLflow**     | http://localhost:5000  | -                              | ML experiment tracking           |
| **RabbitMQ**   | http://localhost:15672 | hotel_user/rabbitmq_password   | Message queue management         |
| **MinIO**      | http://localhost:9001  | minio_admin/minio_password_123 | Object storage console           |
| **Prometheus** | http://localhost:9090  | -                              | Metrics collection               |
| **PostgreSQL** | localhost:5433         | hotel_user/hotel_password      | Main database                    |
| **Redis**      | localhost:6379         | redis_password                 | Cache & messaging                |

### Databases Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng

- `hotel_db` - Main application database
- `prefect_db` - Prefect orchestration
- `grafana_db` - Grafana dashboards
- `mlflow_db` - MLflow experiments
- `vector_db` - Vector embeddings (pgvector)

---

## ğŸ”„ Quáº£n lÃ½ Prefect Flows

### Auto-deploy khi container start

Má»—i khi `prefect-worker` container khá»Ÿi Ä‘á»™ng, nÃ³ sáº½ **tá»± Ä‘á»™ng deploy** táº¥t cáº£ flows Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trong `prefect.yaml`.

### ThÃªm flow má»›i

**BÆ°á»›c 1:** Táº¡o file flow trong `src/flow/`

```python
# src/flow/example_flow.py
from prefect import flow, task
import time

@task(name="process_data", retries=2)
def process_data(data: dict):
    print(f"Processing: {data}")
    return {"status": "processed", "data": data}

@flow(name="example-flow", log_prints=True)
def example_flow(input_data: dict = {}):
    """Example Prefect flow"""
    print("ğŸš€ Starting example flow")
    result = process_data(input_data)
    print(f"âœ… Completed: {result}")
    return result

if __name__ == "__main__":
    example_flow({"test": "data"})
```

**BÆ°á»›c 2:** ThÃªm deployment vÃ o `prefect.yaml`

```yaml
deployments:
  - name: hello-deployment
    entrypoint: src/flow/hello_flow.py:hello_flow
    work_pool:
      name: local-pool
      work_queue_name: default
    tags:
      - hotel
      - production

  # ThÃªm deployment má»›i
  - name: example-deployment
    entrypoint: src/flow/example_flow.py:example_flow
    work_pool:
      name: local-pool
    parameters:
      input_data: { "default": "value" }
    schedule:
      cron: "0 */2 * * *" # Cháº¡y má»—i 2 giá»
    tags:
      - hotel
      - example
```

**BÆ°á»›c 3:** Restart worker Ä‘á»ƒ auto-deploy

```bash
docker compose restart prefect-worker

# Hoáº·c deploy manual (khÃ´ng cáº§n restart)
docker exec hotel-prefect-worker prefect deploy --all
```

**BÆ°á»›c 4:** Cháº¡y flow

```bash
# Cháº¡y tá»« CLI
docker exec hotel-prefect-worker prefect deployment run 'example-flow/example-deployment'

# Hoáº·c tá»« Prefect UI: http://localhost:4200/deployments
```

### Test flow locally (khÃ´ng cáº§n deploy)

```bash
docker exec hotel-prefect-worker python src/flow/example_flow.py
```

---

## ğŸ› ï¸ Development Workflow

### 1. Cáº¥u trÃºc FastAPI Routing

Há»‡ thá»‘ng sá»­ dá»¥ng pattern **centralized routing** vá»›i `main.py` lÃ m entry point:

**`src/application/main.py`** - FastAPI app chÃ­nh:

```python
from fastapi import FastAPI
from src.application.controllers.cv import router as cv_router
from src.application.controllers.ml import router as ml_router
from src.application.controllers.llm import router as llm_router

app = FastAPI(
    title="Hotel AI System",
    description="AI services for hotel management",
    version="1.0.0"
)

# Include all service routers
app.include_router(cv_router.router, prefix="/cv", tags=["Computer Vision"])
app.include_router(ml_router.router, prefix="/ml", tags=["Machine Learning"])
app.include_router(llm_router.router, prefix="/llm", tags=["LLM"])

@app.get("/")
def root():
    return {"message": "Hotel AI System", "status": "running"}

@app.get("/health")
def health_check():
    return {"status": "healthy"}
```

**`src/application/controllers/cv/router.py`** - CV service routes:

```python
from fastapi import APIRouter, UploadFile
from src.application.dtos.cv import FaceRecognitionRequest, FaceRecognitionResponse
from src.application.services.cv import face_recognition_service

router = APIRouter()

@router.post("/face-recognition", response_model=FaceRecognitionResponse)
async def recognize_face(file: UploadFile):
    """Nháº­n diá»‡n khuÃ´n máº·t tá»« áº£nh upload"""
    result = await face_recognition_service.recognize(file)
    return result

@router.post("/ocr")
async def extract_text(file: UploadFile):
    """TrÃ­ch xuáº¥t text tá»« áº£nh (OCR)"""
    # Implementation
    pass
```

**`src/application/controllers/ml/router.py`** - ML service routes:

```python
from fastapi import APIRouter
from src.application.dtos.ml import PricingRequest, PricingResponse
from src.application.services.ml import pricing_service

router = APIRouter()

@router.post("/pricing/predict", response_model=PricingResponse)
async def predict_price(request: PricingRequest):
    """Dá»± Ä‘oÃ¡n giÃ¡ phÃ²ng tá»‘i Æ°u"""
    result = await pricing_service.predict(request)
    return result

@router.post("/recommendation")
async def recommend_rooms(user_id: str):
    """Gá»£i Ã½ phÃ²ng cho khÃ¡ch hÃ ng"""
    # Implementation
    pass
```

**`src/application/controllers/llm/router.py`** - LLM service routes:

```python
from fastapi import APIRouter
from src.application.dtos.llm import ChatRequest, ChatResponse
from src.application.services.llm import chatbot_service

router = APIRouter()

@router.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """Chatbot vá»›i RAG"""
    result = await chatbot_service.query(request.message)
    return result

@router.post("/embeddings")
async def create_embeddings(texts: list[str]):
    """Táº¡o embeddings cho texts"""
    # Implementation
    pass
```

**Routing structure:**

```
GET  /                          â†’ Root endpoint
GET  /health                    â†’ Health check
GET  /docs                      â†’ Swagger UI (auto-generated)

POST /cv/face-recognition       â†’ CV service
POST /cv/ocr                    â†’ CV service

POST /ml/pricing/predict        â†’ ML service
POST /ml/recommendation         â†’ ML service

POST /llm/chat                  â†’ LLM service
POST /llm/embeddings            â†’ LLM service
```

### 2. Sá»­a code flow

File flow Ä‘Æ°á»£c mount vÃ o container qua volumes, nÃªn **khÃ´ng cáº§n rebuild** khi sá»­a code:

```bash
# Sá»­a file
vim src/flow/hello_flow.py

# Restart worker Ä‘á»ƒ deploy láº¡i
docker compose restart prefect-worker
```

### 2. ThÃªm dependencies má»›i

**BÆ°á»›c 1:** Sá»­a `pyproject.toml`

```toml
[project]
dependencies = [
    "prefect>=3.0.0",
    "pandas>=2.0.0",      # ThÃªm dependency má»›i
]
```

**BÆ°á»›c 2:** Rebuild worker

```bash
docker compose up -d --build prefect-worker
```

### 3. Xem logs

```bash
# Táº¥t cáº£ logs
docker compose logs -f

# Chá»‰ Prefect worker
docker compose logs -f prefect-worker

# Logs cá»§a 1 flow run cá»¥ thá»ƒ
# Xem trong Prefect UI: http://localhost:4200/runs
```

### 4. Dá»n dáº¹p

```bash
# Stop táº¥t cáº£ services
docker compose down

# Stop vÃ  xÃ³a volumes (XÃ“A Dá»® LIá»†U!)
docker compose down -v

# Rebuild tá»« Ä‘áº§u
docker compose up -d --build --force-recreate
```

---

## ğŸ¤– RAG Implementation vá»›i LlamaIndex

### Setup pgvector Vector Store

**BÆ°á»›c 1:** ThÃªm dependencies vÃ o `pyproject.toml`

```toml
[project]
dependencies = [
    "prefect>=3.0.0",
    "llama-index>=0.10.0",
    "llama-index-vector-stores-postgres>=0.1.0",
    "psycopg2-binary>=2.9.0",
    "openai>=1.0.0",
]
```

**BÆ°á»›c 2:** Táº¡o vector store service

```python
# src/application/services/llm/vector_store.py
from llama_index.core import VectorStoreIndex, StorageContext
from llama_index.vector_stores.postgres import PGVectorStore
from llama_index.core.node_parser import SimpleNodeParser
from llama_index.core import Document

class HotelVectorStore:
    def __init__(self):
        self.vector_store = PGVectorStore.from_params(
            database="vector_db",
            host="postgres",
            password="hotel_password",
            port=5432,
            user="hotel_user",
            table_name="hotel_embeddings",
            embed_dim=1536,
        )

        self.storage_context = StorageContext.from_defaults(
            vector_store=self.vector_store
        )

    def index_documents(self, documents: list[str]):
        """Index documents into vector store"""
        docs = [Document(text=text) for text in documents]
        index = VectorStoreIndex.from_documents(
            docs,
            storage_context=self.storage_context
        )
        return index

    def query(self, question: str, top_k: int = 5):
        """Query the vector store"""
        index = VectorStoreIndex.from_vector_store(
            self.vector_store,
            storage_context=self.storage_context
        )
        query_engine = index.as_query_engine(similarity_top_k=top_k)
        response = query_engine.query(question)
        return response
```

**BÆ°á»›c 3:** Táº¡o Prefect flow Ä‘á»ƒ index documents

```python
# src/flow/rag_indexing_flow.py
from prefect import flow, task
from src.application.services.llm.vector_store import HotelVectorStore

@task(name="load_hotel_documents", retries=2)
def load_documents():
    """Load hotel documents from database or files"""
    documents = [
        "Check-in time is 3:00 PM. Early check-in subject to availability.",
        "Check-out time is 11:00 AM. Late check-out available for extra fee.",
        "Free WiFi available in all rooms and common areas.",
        "Swimming pool open from 6:00 AM to 10:00 PM daily.",
    ]
    return documents

@task(name="index_to_vector_store")
def index_documents(documents: list[str]):
    """Index documents to pgvector"""
    vector_store = HotelVectorStore()
    index = vector_store.index_documents(documents)
    print(f"âœ… Indexed {len(documents)} documents")
    return True

@flow(name="rag-indexing-flow", log_prints=True)
def rag_indexing_flow():
    """Index hotel documents for RAG"""
    print("ğŸ”„ Loading documents...")
    docs = load_documents()

    print("ğŸ“š Indexing to vector store...")
    index_documents(docs)

    print("âœ… RAG indexing completed!")

if __name__ == "__main__":
    rag_indexing_flow()
```

**BÆ°á»›c 4:** Táº¡o RAG query flow

```python
# src/flow/rag_query_flow.py
from prefect import flow, task
from src.application.services.llm.vector_store import HotelVectorStore

@task(name="query_vector_store")
def query_rag(question: str):
    """Query RAG system"""
    vector_store = HotelVectorStore()
    response = vector_store.query(question)
    return str(response)

@flow(name="rag-query-flow", log_prints=True)
def rag_query_flow(question: str):
    """Query hotel information using RAG"""
    print(f"â“ Question: {question}")

    answer = query_rag(question)

    print(f"âœ… Answer: {answer}")
    return answer

if __name__ == "__main__":
    rag_query_flow("What time is check-in?")
```

**BÆ°á»›c 5:** Deploy RAG flows

ThÃªm vÃ o `prefect.yaml`:

```yaml
deployments:
  # ... existing deployments

  - name: rag-indexing
    entrypoint: src/flow/rag_indexing_flow.py:rag_indexing_flow
    work_pool:
      name: local-pool
    schedule:
      cron: "0 2 * * *" # Index má»—i ngÃ y lÃºc 2 AM
    tags:
      - rag
      - indexing

  - name: rag-query
    entrypoint: src/flow/rag_query_flow.py:rag_query_flow
    work_pool:
      name: local-pool
    tags:
      - rag
      - query
```

### Kiá»ƒm tra pgvector tables

```bash
# Connect vÃ o PostgreSQL
docker exec -it hotel-postgres psql -U hotel_user -d vector_db

# List tables
\dt

# View embeddings table structure
\d hotel_embeddings

# Query vectors
SELECT id, metadata, embedding FROM hotel_embeddings LIMIT 5;
```

### Monitoring RAG Performance

```python
# ThÃªm logging vÃ  metrics
from prefect import flow, task
import time

@task(name="query_with_metrics")
def query_with_metrics(question: str):
    start_time = time.time()

    vector_store = HotelVectorStore()
    response = vector_store.query(question)

    elapsed = time.time() - start_time
    print(f"â±ï¸  Query time: {elapsed:.2f}s")

    return {
        "answer": str(response),
        "query_time": elapsed,
        "question": question
    }
```

---

## ğŸ”§ Troubleshooting

### âŒ Container restart liÃªn tá»¥c

**Kiá»ƒm tra logs:**

```bash
docker logs hotel-prefect-worker --tail 50
```

**NguyÃªn nhÃ¢n thÆ°á»ng gáº·p:**

- Database chÆ°a sáºµn sÃ ng â†’ Äá»£i thÃªm vÃ i giÃ¢y
- Port conflict â†’ Äá»•i port trong `docker-compose.yml`
- Thiáº¿u dependencies â†’ Rebuild image

### âŒ Port 5432 already in use

PostgreSQL local Ä‘ang cháº¡y. Há»‡ thá»‘ng Ä‘Ã£ map port `5433:5432` Ä‘á»ƒ trÃ¡nh conflict.

```bash
# Káº¿t ná»‘i tá»« host
psql -h localhost -p 5433 -U hotel_user -d hotel_db

# Hoáº·c stop PostgreSQL local
brew services stop postgresql  # macOS
sudo systemctl stop postgresql  # Linux
```

### âŒ Flow khÃ´ng tá»± Ä‘á»™ng deploy

**Kiá»ƒm tra:**

```bash
# Xem logs deploy
docker logs hotel-prefect-worker | grep -A 10 "Deploying"

# Validate prefect.yaml
docker exec hotel-prefect-worker prefect deploy --all
```

**Lá»—i thÆ°á»ng gáº·p:**

- Sai format `entrypoint` trong `prefect.yaml`
- Flow import bá»‹ lá»—i (syntax error)
- Work pool chÆ°a tá»“n táº¡i (tá»± táº¡o náº¿u chÆ°a cÃ³)

### âŒ Cannot connect to Prefect server

**Kiá»ƒm tra:**

```bash
# Test tá»« host
curl http://localhost:4200/api/health

# Test tá»« worker container
docker exec hotel-prefect-worker curl http://prefect-server:4200/api/health
```

**Fix:**

```bash
# Restart Prefect server
docker compose restart prefect-server prefect-services

# Kiá»ƒm tra database connection
docker logs hotel-prefect-server | grep -i error
```

### âŒ MLflow: No module named 'psycopg2'

ÄÃ£ fix báº±ng cÃ¡ch cÃ i `psycopg2-binary` trong docker-compose command. Náº¿u váº«n lá»—i:

```bash
docker compose down
docker compose up -d --build mlflow
```

### ğŸ” Debug mode

Báº­t debug logs cho Prefect:

```bash
# ThÃªm vÃ o docker-compose.yml > prefect-worker > environment
PREFECT_LOGGING_LEVEL=DEBUG
```

---

## ğŸ“š TÃ i liá»‡u thÃªm

- **Architecture**: `docs/HOTEL_SYSTEM_ARCHITECTURE.md`
- **CV Service**: `docs/CV_SERVICE.md`
- **ML Service**: `docs/ML_SERVICE.md`
- **LLM Service**: `docs/LLM_SERVICE.md`
- **Prefect Service**: `docs/PREFECT_SERVICE.md`
- **Deployment**: `docs/DEPLOYMENT_ROADMAP.md`

---

## ğŸ“ Notes

- **.env file**: KhÃ´ng commit file nÃ y vÃ o Git (Ä‘Ã£ cÃ³ trong `.gitignore`)
- **Hot reload**: Code trong `src/` Ä‘Æ°á»£c mount vÃ o container, sá»­a code khÃ´ng cáº§n rebuild
- **Production**: Äá»•i táº¥t cáº£ passwords trong `.env` vÃ  `docker-compose.yml`
- **Security**: Trong production nÃªn dÃ¹ng secrets manager (AWS Secrets, Vault)

---

## ğŸ¤ Contributing

1. Táº¡o branch má»›i: `git checkout -b feature/ten-feature`
2. Commit changes: `git commit -m "Add feature"`
3. Push: `git push origin feature/ten-feature`
4. Táº¡o Pull Request

---

## ğŸ“„ License

Copyright Â© 2025 Hotel AI Management System
